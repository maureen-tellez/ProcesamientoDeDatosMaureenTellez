{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "kYmgbnGytC9h"
   },
   "outputs": [],
   "source": [
    "#@title Copyright 2023 Google LLC. Double-click for license information.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeNGK50ZP5pR"
   },
   "source": [
    "# Clasificación binaria \n",
    "\n",
    "En este notebook, completarás las siguientes tareas:\n",
    "\n",
    "- Examinar un conjunto de datos que contiene mediciones derivadas de imágenes de dos especies de arroz turco.\n",
    "- Crear un clasificador binario para clasificar los granos de arroz en las dos especies.\n",
    "- Evaluar el rendimiento del modelo.\n",
    "\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "Al completar este notebook, aprenderás:\n",
    "\n",
    "- Cómo entrenar un clasificador binario.\n",
    "- Cómo calcular métricas para un clasificador binario en diferentes umbrales.\n",
    "- Cómo comparar AUC y ROC de dos modelos diferentes.\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Este Notebook utiliza el conjunto de datos de arroz Cinar y Koklu 2019 Osmancik y Cammeo.\n",
    "\n",
    "Se proporciona una licencia CC0 (consulte [Kaggle](https://www.kaggle.com/datasets/muratkokludataset/rice-dataset-commeo-and-osmancik)para obtener más documentación; las longitudes y el área se dan en píxeles). Cinar y Koklu también proporcionan conjuntos de datos para multiclase (5 especies de arroz), pistachos, pasas, hojas de uva, etc., en su [repositorio](https://www.muratkoklu.com/datasets/).\n",
    "\n",
    "### Cita\n",
    "\n",
    "Cinar, I. and Koklu, M., (2019). “Classification of Rice Varieties Using Artificial Intelligence Methods.” *International Journal of Intelligent Systems and Applications in Engineering*, 7(3), 188-194.\n",
    "\n",
    "DOI: https://doi.org/10.18201/ijisae.2019355381\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4JwY1X5iryL"
   },
   "source": [
    "# Instalar bibliotecas requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install required libraries\n",
    "\n",
    "!pip install google-ml-edu==0.1.2 \\\n",
    "    keras~=3.8.0 \\\n",
    "    matplotlib~=3.10.0 \\\n",
    "    numpy~=2.0.0 \\\n",
    "    pandas~=2.2.0 \\\n",
    "    tensorflow~=2.18.0\n",
    "\n",
    "print('\\n\\nAll requirements successfully installed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load the imports\n",
    "\n",
    "import keras\n",
    "import ml_edu.experiment\n",
    "import ml_edu.results\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# The following lines adjust the granularity of reporting.\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "print(\"Ran the import statements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDobhxERWPD1"
   },
   "outputs": [],
   "source": [
    "# @title Load the dataset\n",
    "rice_dataset_raw = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/Rice_Cammeo_Osmancik.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IqvqOvaQqlK"
   },
   "source": [
    "Una vez que el conjunto de datos se haya cargado a través de la celda anterior, seleccione columnas específicas para mostrar estadísticas de resumen de las características numéricas del conjunto de datos.\n",
    "\n",
    "Consulte la  [dataset documentation](https://www.kaggle.com/datasets/muratkokludataset/rice-dataset-commeo-and-osmancik), especialmente la sección **Procedencia**, para obtener explicaciones de lo que significa cada característica y cómo se calcularon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKakOMCmHp-E"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Read and provide statistics on the dataset.\n",
    "rice_dataset = rice_dataset_raw[[\n",
    "    'Area',\n",
    "    'Perimeter',\n",
    "    'Major_Axis_Length',\n",
    "    'Minor_Axis_Length',\n",
    "    'Eccentricity',\n",
    "    'Convex_Area',\n",
    "    'Extent',\n",
    "    'Class',\n",
    "]]\n",
    "\n",
    "rice_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynv9WwTPG9oU"
   },
   "source": [
    "## Tarea 1: Describir los datos\n",
    "\n",
    "De las estadísticas de resumen anteriores, responda las siguientes preguntas:\n",
    "\n",
    "- ¿Cuáles son las longitudes mínima y máxima (longitud del eje principal, dada en píxeles) de los granos de arroz?\n",
    "- ¿Cuál es la gama de áreas entre los granos de arroz más pequeños y más grandes?\n",
    "- ¿Cuántas desviaciones estándar (std) ¿es el mayor perímetro de grano de arroz de la media?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y36kQm1vJ7n3"
   },
   "outputs": [],
   "source": [
    "# @title Solutions (run the cell to get the answers)\n",
    "\n",
    "print(\n",
    "    f'The shortest grain is {rice_dataset.Major_Axis_Length.min():.1f}px long,'\n",
    "    f' while the longest is {rice_dataset.Major_Axis_Length.max():.1f}px.'\n",
    ")\n",
    "print(\n",
    "    f'The smallest rice grain has an area of {rice_dataset.Area.min()}px, while'\n",
    "    f' the largest has an area of {rice_dataset.Area.max()}px.'\n",
    ")\n",
    "print(\n",
    "    'The largest rice grain, with a perimeter of'\n",
    "    f' {rice_dataset.Perimeter.max():.1f}px, is'\n",
    "    f' ~{(rice_dataset.Perimeter.max() - rice_dataset.Perimeter.mean())/rice_dataset.Perimeter.std():.1f} standard'\n",
    "    f' deviations ({rice_dataset.Perimeter.std():.1f}) from the mean'\n",
    "    f' ({rice_dataset.Perimeter.mean():.1f}px).'\n",
    ")\n",
    "print(\n",
    "    f'This is calculated as: ({rice_dataset.Perimeter.max():.1f} -'\n",
    "    f' {rice_dataset.Perimeter.mean():.1f})/{rice_dataset.Perimeter.std():.1f} ='\n",
    "    f' {(rice_dataset.Perimeter.max() - rice_dataset.Perimeter.mean())/rice_dataset.Perimeter.std():.1f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bc8JVgN2j6h3"
   },
   "source": [
    "# Explore el conjunto de datos\n",
    "\n",
    "Traza algunas de las características unas contra otras, incluso en 3D.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNw5U7-4NFLR"
   },
   "outputs": [],
   "source": [
    "# Create five 2D plots of the features against each other, color-coded by class.\n",
    "for x_axis_data, y_axis_data in [\n",
    "    ('Area', 'Eccentricity'),\n",
    "    ('Convex_Area', 'Perimeter'),\n",
    "    ('Major_Axis_Length', 'Minor_Axis_Length'),\n",
    "    ('Perimeter', 'Extent'),\n",
    "    ('Eccentricity', 'Major_Axis_Length'),\n",
    "]:\n",
    "  px.scatter(rice_dataset, x=x_axis_data, y=y_axis_data, color='Class').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6xJ0HQxLB4N"
   },
   "source": [
    "## Task 2: Tarea 2: Visualizar muestras en 3D\n",
    "\n",
    "Intente graficar tres de las características en 3D entre sí.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvpUsZF1LDWM"
   },
   "outputs": [],
   "source": [
    "#@title Plot three features in 3D by entering their names and running this cell\n",
    "\n",
    "x_axis_data = 'Enter a feature name here'  # @param {type: \"string\"}\n",
    "y_axis_data = 'Enter a feature name here'  # @param {type: \"string\"}\n",
    "z_axis_data = 'Enter a feature name here'  # @param {type: \"string\"}\n",
    "\n",
    "px.scatter_3d(\n",
    "    rice_dataset,\n",
    "    x=x_axis_data,\n",
    "    y=y_axis_data,\n",
    "    z=z_axis_data,\n",
    "    color='Class',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "r5WBGiJChXt-"
   },
   "outputs": [],
   "source": [
    "# @title One possible solution\n",
    "\n",
    "# Plot major and minor axis length and eccentricity, with observations\n",
    "# color-coded by class.\n",
    "px.scatter_3d(\n",
    "    rice_dataset,\n",
    "    x='Eccentricity',\n",
    "    y='Area',\n",
    "    z='Major_Axis_Length',\n",
    "    color='Class',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ch82395CSBMR"
   },
   "source": [
    "Si tuviéramos que elegir tres características, parece que la longitud del eje mayor, el área y la excentricidad podrían contener la mayor parte de la información que diferencia a las dos clases. Otras combinaciones también pueden funcionar.\n",
    "\n",
    "Ejecute la celda de código anterior para graficar esas tres características si aún no lo ha hecho.\n",
    "\n",
    "Parece que un límite de clase distinto aparece en el plano de estas tres características. Entrenaremos un modelo solo en estas características, luego otro modelo en el conjunto completo de características, y compararemos su rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G6y-XcEmk6r"
   },
   "source": [
    "## Normalize data\n",
    "\n",
    "Normalizar los datos\n",
    "\n",
    "Al crear un modelo con múltiples características, los valores de cada característica deben abarcar aproximadamente el mismo rango. Si los valores de una característica oscilan entre 500 y 100.000 y los valores de otra característica oscilan entre 2 y 12, el modelo necesitará tener pesos de valores extremadamente bajos o extremadamente altos para poder combinar estas características de manera efectiva. Esto podría resultar en un modelo de baja calidad. Para evitar esto,\n",
    "[normalizar](https://developers.google.com/machine-learning/glossary/#normalization) las características en un modelo multi-función.\n",
    "\n",
    "Esto se puede hacer convirtiendo cada valor bruto en su **puntuación Z**. La puntuación Z para un valor dado es cuántas desviaciones estándar de la media es el valor.\n",
    "\n",
    "Considere una característica con una media de 60 y una desviación estándar de 10.\n",
    "\n",
    "El valor bruto 75 tendría una puntuación Z de +1.5:\n",
    "\n",
    "```\n",
    "  Z-score = (75 - 60) / 10 = +1.5\n",
    "```\n",
    "\n",
    "El valor bruto 38 tendría una puntuación Z de -2.2:\n",
    "\n",
    "```\n",
    "  Z-score = (38 - 60) / 10 = -2.2\n",
    "```\n",
    "\n",
    "Ahora normaliza los valores numéricos en el conjunto de datos de arroz convirtiéndolos en puntuaciones Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSUjPSwNiyBP"
   },
   "outputs": [],
   "source": [
    "# Calculate the Z-scores of each numerical column in the raw data and write\n",
    "# them into a new DataFrame named df_norm.\n",
    "\n",
    "feature_mean = rice_dataset.mean(numeric_only=True)\n",
    "feature_std = rice_dataset.std(numeric_only=True)\n",
    "numerical_features = rice_dataset.select_dtypes('number').columns\n",
    "normalized_dataset = (\n",
    "    rice_dataset[numerical_features] - feature_mean\n",
    ") / feature_std\n",
    "\n",
    "# Copy the class to the new dataframe\n",
    "normalized_dataset['Class'] = rice_dataset['Class']\n",
    "\n",
    "# Examine some of the values of the normalized training set. Notice that most\n",
    "# Z-scores fall between -2 and +2.\n",
    "normalized_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5aXjXq-YIkL"
   },
   "source": [
    "# Establecer las semillas aleatorias \n",
    "\n",
    "Para hacer que los experimentos sean reproducibles, establecemos la semilla de los generadores de números aleatorios. Esto significa que el orden en el que se barajan los datos, los valores de las inicializaciones de peso aleatorio, etc., serán todos iguales cada vez que se ejecute el colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bu257GAFYH-N"
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7M9I-ekT1dV"
   },
   "source": [
    "## Etiqueta y divide los datos\n",
    "\n",
    "Para entrenar el modelo, asignaremos arbitrariamente a la especie Cammeo una etiqueta de '1' y la especie Osmancik una etiqueta de '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4_yTxWdvPqz"
   },
   "outputs": [],
   "source": [
    "# Create a column setting the Cammeo label to '1' and the Osmancik label to '0'\n",
    "# then show 10 randomly selected rows.\n",
    "normalized_dataset['Class_Bool'] = (\n",
    "    # Returns true if class is Cammeo, and false if class is Osmancik\n",
    "    normalized_dataset['Class'] == 'Cammeo'\n",
    ").astype(int)\n",
    "normalized_dataset.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBY8b0akUqiQ"
   },
   "source": [
    "A continuación, podemos aleatorizar y dividir el conjunto de datos en tren, validación y divisiones de prueba, que consisten en 80%, 10% y 10% del conjunto de datos, respectivamente.\n",
    "\n",
    "Utilizaremos los datos de entrenamiento para aprender los parámetros del modelo, luego usaremos los datos de validación para evaluar diferentes modelos y, finalmente, usaremos los datos de prueba para calcular las métricas finales para el modelo que mejor se desempeñó en los datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XE-RAq0av1wv"
   },
   "outputs": [],
   "source": [
    "# Create indices at the 80th and 90th percentiles\n",
    "number_samples = len(normalized_dataset)\n",
    "index_80th = round(number_samples * 0.8)\n",
    "index_90th = index_80th + round(number_samples * 0.1)\n",
    "\n",
    "# Randomize order and split into train, validation, and test with a .8, .1, .1 split\n",
    "shuffled_dataset = normalized_dataset.sample(frac=1, random_state=100)\n",
    "train_data = shuffled_dataset.iloc[0:index_80th]\n",
    "validation_data = shuffled_dataset.iloc[index_80th:index_90th]\n",
    "test_data = shuffled_dataset.iloc[index_90th:]\n",
    "\n",
    "# Show the first five rows of the last split\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Iq_haqJYeSH"
   },
   "source": [
    "Es importante evitar que el modelo obtenga la etiqueta como entrada durante el entrenamiento, lo que se llama fuga de etiqueta. Esto se puede hacer almacenando características y etiquetas como variables separadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Gi0VaAAYiaO"
   },
   "outputs": [],
   "source": [
    "label_columns = ['Class', 'Class_Bool']\n",
    "\n",
    "train_features = train_data.drop(columns=label_columns)\n",
    "train_labels = train_data['Class_Bool'].to_numpy()\n",
    "validation_features = validation_data.drop(columns=label_columns)\n",
    "validation_labels = validation_data['Class_Bool'].to_numpy()\n",
    "test_features = test_data.drop(columns=label_columns)\n",
    "test_labels = test_data['Class_Bool'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-kTF2rTY-K8"
   },
   "source": [
    "## Entrena el modelo\n",
    "\n",
    "### Elige las características de entrada\n",
    "\n",
    "Para empezar, vamos a entrenar a un modelo en `Eccentricity`, `Major_Axis_Length,` y `Area`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v_UNIPBtjoz"
   },
   "outputs": [],
   "source": [
    "# Name of the features we'll train our model on.\n",
    "input_features = [\n",
    "    'Eccentricity',\n",
    "    'Major_Axis_Length',\n",
    "    'Area',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSBegHR5rSEn"
   },
   "source": [
    "## Definir funciones que construyan y entrenen un modelo \n",
    "\n",
    "La siguiente celda de código define dos funciones:\n",
    "\n",
    "  * `create_model(inputs, learning_rate, metrics)`, que define la arquitectura del modelo.\n",
    "  * `train_model(model, dataset, epochs, label_name, batch_size, shuffle)`, utiliza características de entrada y etiquetas para entrenar el modelo.\n",
    "\n",
    "Nota: create_model aplica la función sigmoide para realizar [logistic regression](https://developers.google.com/machine-learning/crash-course/logistic-regression).\n",
    "\n",
    "También definimos dos estructuras de datos útiles: `ExperimentSettings` y `Experiment`. Utilizamos estas sencillas clases para realizar un seguimiento de nuestros experimentos, permitiéndonos saber qué hiperparámetros se utilizaron y cuáles fueron los resultados. En `ExperimentSettings`, almacenamos todos los valores que describen un experimento (es decir, hiperparámetros). Luego, almacenamos los resultados de una carrera de entrenamiento (es decir, el modelo y las métricas de entrenamiento) en una `Experiment`, junto con el `ExperimentSettings` se utiliza para ese experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8B2VArcKH6UX"
   },
   "outputs": [],
   "source": [
    "# @title Define the functions that create and train a model.\n",
    "\n",
    "\n",
    "def create_model(\n",
    "    settings: ml_edu.experiment.ExperimentSettings,\n",
    "    metrics: list[keras.metrics.Metric],\n",
    ") -> keras.Model:\n",
    "  \"\"\"Create and compile a simple classification model.\"\"\"\n",
    "  model_inputs = [\n",
    "      keras.Input(name=feature, shape=(1,))\n",
    "      for feature in settings.input_features\n",
    "  ]\n",
    "  # Use a Concatenate layer to assemble the different inputs into a single\n",
    "  # tensor which will be given as input to the Dense layer.\n",
    "  # For example: [input_1[0][0], input_2[0][0]]\n",
    "\n",
    "  concatenated_inputs = keras.layers.Concatenate()(model_inputs)\n",
    "  model_output = keras.layers.Dense(\n",
    "      units=1, name='dense_layer', activation=keras.activations.sigmoid\n",
    "  )(concatenated_inputs)\n",
    "  model = keras.Model(inputs=model_inputs, outputs=model_output)\n",
    "  # Call the compile method to transform the layers into a model that\n",
    "  # Keras can execute.  Notice that we're using a different loss\n",
    "  # function for classification than for regression.\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.RMSprop(\n",
    "          settings.learning_rate\n",
    "      ),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics,\n",
    "  )\n",
    "  return model\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    experiment_name: str,\n",
    "    model: keras.Model,\n",
    "    dataset: pd.DataFrame,\n",
    "    labels: np.ndarray,\n",
    "    settings: ml_edu.experiment.ExperimentSettings,\n",
    ") -> ml_edu.experiment.Experiment:\n",
    "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "  # The x parameter of keras.Model.fit can be a list of arrays, where\n",
    "  # each array contains the data for one feature.\n",
    "  features = {\n",
    "      feature_name: np.array(dataset[feature_name])\n",
    "      for feature_name in settings.input_features\n",
    "  }\n",
    "\n",
    "  history = model.fit(\n",
    "      x=features,\n",
    "      y=labels,\n",
    "      batch_size=settings.batch_size,\n",
    "      epochs=settings.number_epochs,\n",
    "  )\n",
    "\n",
    "  return ml_edu.experiment.Experiment(\n",
    "      name=experiment_name,\n",
    "      settings=settings,\n",
    "      model=model,\n",
    "      epochs=history.epoch,\n",
    "      metrics_history=pd.DataFrame(history.history),\n",
    "  )\n",
    "\n",
    "\n",
    "print('Defined the create_model and train_model functions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ak_TMAzGOIFq"
   },
   "source": [
    "## Definir una función de trazado\n",
    "\n",
    "La siguiente función [matplotlib](https://developers.google.com/machine-learning/glossary/#matplotlib) traza una o más curvas, mostrando cómo cambian varias métricas de clasificación con cada época."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-IXYVfvM4gD"
   },
   "source": [
    "## Invocar las funciones de creación, entrenamiento y trazado\n",
    "\n",
    "El siguiente código especifica los hiperparámetros, invoca el Funciones para crear y entrenar el modelo, luego traza los resultados, incluyendo la precisión, la precisión y el recuerdo.\n",
    "\n",
    "El umbral de clasificación se establece en 0.35. Intente jugar con el umbral, luego la tasa de aprendizaje, para ver qué cambia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q82E6tS13O_2"
   },
   "outputs": [],
   "source": [
    "# Let's define our first experiment settings.\n",
    "settings = ml_edu.experiment.ExperimentSettings(\n",
    "    learning_rate=0.001,\n",
    "    number_epochs=60,\n",
    "    batch_size=100,\n",
    "    classification_threshold=0.35,\n",
    "    input_features=input_features,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.BinaryAccuracy(\n",
    "        name='accuracy', threshold=settings.classification_threshold\n",
    "    ),\n",
    "    keras.metrics.Precision(\n",
    "        name='precision', thresholds=settings.classification_threshold\n",
    "    ),\n",
    "    keras.metrics.Recall(\n",
    "        name='recall', thresholds=settings.classification_threshold\n",
    "    ),\n",
    "    keras.metrics.AUC(num_thresholds=100, name='auc'),\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "model = create_model(settings, metrics)\n",
    "\n",
    "# Train the model on the training set.\n",
    "experiment = train_model(\n",
    "    'baseline', model, train_features, train_labels, settings\n",
    ")\n",
    "\n",
    "# Plot metrics vs. epochs\n",
    "ml_edu.results.plot_experiment_metrics(experiment, ['accuracy', 'precision', 'recall'])\n",
    "ml_edu.results.plot_experiment_metrics(experiment, ['auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfxkB-_vwUwq"
   },
   "source": [
    "El AUC se calcula a través de todos los umbrales posibles (en la práctica en el código anterior, 100 umbrales), mientras que la precisión, la precisión y la recuperación se calculan solo para el umbral especificado. Por esta razón se muestran por separado arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8y8vKBGsv0m"
   },
   "source": [
    "## Evaluar el modelo frente al conjunto validación \n",
    "\n",
    "Al final del *entrenamiento* del modelo, terminaste con una cierta precisión contra el *conjunto de entrenamiento*. Invoque la siguiente celda de código para determinar la precisión de su modelo con el *conjunto de validación*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHh53BX44R94"
   },
   "outputs": [],
   "source": [
    "def compare_train_validation(experiment: ml_edu.experiment.Experiment, validation_metrics: dict[str, float]):\n",
    "  print('Comparing metrics between train and validation:')\n",
    "  for metric, validation_value in validation_metrics.items():\n",
    "    print('------')\n",
    "    print(f'Train {metric}: {experiment.get_final_metric_value(metric):.4f}')\n",
    "    print(f'Validation {metric}:  {validation_value:.4f}')\n",
    "\n",
    "\n",
    "# Evaluate validation metrics\n",
    "validation_metrics = experiment.evaluate(validation_features, validation_labels)\n",
    "compare_train_validation(experiment, validation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ku6nq9KDtL6u"
   },
   "source": [
    "Parece que el modelo, que alcanzó una precisión de ~92% en los datos de entrenamiento, todavía muestra una precisión de aproximadamente el 90% en los datos de validación. ¿Podemos hacerlo mejor? Entrenemos un modelo utilizando las siete características disponibles y comparemos las AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72Mfkp3RxQii"
   },
   "outputs": [],
   "source": [
    "# Features used to train the model on.\n",
    "# Specify all features.\n",
    "all_input_features = [\n",
    "  'Eccentricity',\n",
    "  'Major_Axis_Length',\n",
    "  'Minor_Axis_Length',\n",
    "  ? Your code here\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "xfdeJjoUNmTv"
   },
   "outputs": [],
   "source": [
    "#@title Solution\n",
    "# Features used to train the model on.\n",
    "# Specify all features.\n",
    "all_input_features = [\n",
    "  'Eccentricity',\n",
    "  'Major_Axis_Length',\n",
    "  'Minor_Axis_Length',\n",
    "  'Area',\n",
    "  'Convex_Area',\n",
    "  'Perimeter',\n",
    "  'Extent',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hql2nxXqxuBg"
   },
   "source": [
    "## Entrena el modelo con todas las funciones y calcula las métricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-85dcJ3ntocd"
   },
   "outputs": [],
   "source": [
    "settings_all_features = ml_edu.experiment.ExperimentSettings(\n",
    "    learning_rate=0.001,\n",
    "    number_epochs=60,\n",
    "    batch_size=100,\n",
    "    classification_threshold=0.5,\n",
    "    input_features=all_input_features,\n",
    ")\n",
    "\n",
    "# Modify the following definition of METRICS to generate\n",
    "# not only accuracy and precision, but also recall:\n",
    "metrics = [\n",
    "    keras.metrics.BinaryAccuracy(\n",
    "        name='accuracy',\n",
    "        threshold=settings_all_features.classification_threshold,\n",
    "    ),\n",
    "    keras.metrics.Precision(\n",
    "        name='precision',\n",
    "        thresholds=settings_all_features.classification_threshold,\n",
    "    ),\n",
    "    keras.metrics.Recall(\n",
    "        name='recall', thresholds=settings_all_features.classification_threshold\n",
    "    ),\n",
    "    keras.metrics.AUC(num_thresholds=100, name='auc'),\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "model_all_features = create_model(settings_all_features, metrics)\n",
    "\n",
    "# Train the model on the training set.\n",
    "experiment_all_features = train_model(\n",
    "    'all features',\n",
    "    model_all_features,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    settings_all_features,\n",
    ")\n",
    "\n",
    "# Plot metrics vs. epochs\n",
    "ml_edu.results.plot_experiment_metrics(\n",
    "    experiment_all_features, ['accuracy', 'precision', 'recall']\n",
    ")\n",
    "ml_edu.results.plot_experiment_metrics(experiment_all_features, ['auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5ndvrnjzXCo"
   },
   "source": [
    "## Evaluar el modelo con todas las funciones en la división de validación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BklcY6pyDrY"
   },
   "outputs": [],
   "source": [
    "validation_metrics_all_features = experiment_all_features.evaluate(\n",
    "    validation_features,\n",
    "    validation_labels,\n",
    ")\n",
    "compare_train_validation(experiment_all_features, validation_metrics_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTr_boLBze2k"
   },
   "source": [
    "Este segundo modelo tiene métricas de tren y validación más cercanas, lo que sugiere que se ajusta menos a los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqgyfbXXawq4"
   },
   "source": [
    "# Comparando nuestros dos modelo\n",
    "\n",
    "Con nuestro marco de experimentación simple, podemos hacer un seguimiento de qué experimentos realizamos y cuáles fueron los resultados. También se definió una función auxiliar que nos permite comparar fácilmente dos o más modelos, tanto durante el entrenamiento como cuando se evalúa en el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhbgA_FEayYU"
   },
   "outputs": [],
   "source": [
    "ml_edu.results.compare_experiment([experiment, experiment_all_features],\n",
    "                                  ['accuracy', 'auc'],\n",
    "                                  validation_features, validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKIuJGOTbNWz"
   },
   "source": [
    "Comparando los dos modelos, ambos tienen AUC de ~.97-.98. No parece haber una gran ganancia en la calidad del modelo al agregar las otras cuatro características, lo que tiene sentido, dado que muchas de las características (área, perímetro y área convexa, por ejemplo) están interrelacionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRRAx9FRWEij"
   },
   "source": [
    "# Computar las métricas finales de la prueba\n",
    "\n",
    "Para estimar la evolución de nuestro modelo sobre datos invisibles, ahora podemos calcular las métricas del mejor modelo en los datos de prueba. Este paso final debe hacerse una vez que la experimentación ha terminado y hemos seleccionado el modelo que queremos utilizar. Cualquier comparación de modelos debe hacerse utilizando el conjunto de validación, para evitar seleccionar accidentalmente un modelo que esté diseñado para nuestro conjunto de prueba.\n",
    "\n",
    "Este paso final también es la oportunidad de verificar el posible sobreajuste: si las métricas de validación y prueba son muy diferentes, podría ser una señal de que el proceso de selección realizado utilizando el conjunto de validación condujo a un modelo que no se generaliza bien, posiblemente porque el conjunto de validación no es representativo de la distribución general de datos. En ese caso, la mejor solución es barajar los datos y reasignar el tren, la validación y los conjuntos de pruebas, antes de ejecutar sus experimentos nuevamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVOCsf-rXSDp"
   },
   "outputs": [],
   "source": [
    "test_metrics_all_features = experiment_all_features.evaluate(\n",
    "    test_features,\n",
    "    test_labels,\n",
    ")\n",
    "for metric, test_value in test_metrics_all_features.items():\n",
    "  print(f'Test {metric}:  {test_value:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7NIsBQUXmw0"
   },
   "source": [
    "En este caso, vemos que la precisión de la prueba es de aproximadamente el 92%, que está cerca de la precisión de validación que hemos obtenido anteriormente. ¡Esto significa que nuestro modelo debe funcionar igualmente bien con datos nuevos e invisibles!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
